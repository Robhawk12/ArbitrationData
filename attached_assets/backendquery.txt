**Goal:** Implement the backend API endpoint for a Natural Language Query feature using the Vercel AI SDK.

**Context:**
*   This is part of an application that analyzes arbitration case data stored in a database.
*   We need a backend API endpoint that accepts a natural language question about the arbitration data and returns a structured answer.
*   This prompt focuses *only* on the backend logic (API route, AI processing, database interaction). No frontend implementation is required.

**Core Requirements (Based on PRD AIQ-02, AIQ-03):**
1.  **API Endpoint:** Create an API endpoint (e.g., `/api/query_ai`) that accepts POST requests. The request body should contain the user's natural language question (e.g., `{ "question": "How many cases did Arbitrator X handle?"}`).
2.  **AI Processing (Vercel AI SDK):**
    *   Use the Vercel AI SDK to interact with an underlying Large Language Model (LLM like OpenAI, Anthropic, etc. - specify below).
    *   **Crucially:** Construct a prompt for the LLM that instructs it to:
        *   Analyze the incoming user question.
        *   **Generate a database query ** based on the question and the existing database schema .
        *   The AI must understand the schema and map natural language concepts (like "arbitrator", "case count", "average award", "respondent") to the correct tables and columns.
	*  Handle similar or synonyms and assign to correct category or entity(ie. 'matters' meaning 'case or cases')
        *   Handle the specific question types: arbitrator case counts (total, by outcome, vs specific respondent), arbitrator average awards, lists of cases for an arbitrator, respondent case counts, lists of arbitrators for a respondent, average awards against a respondent.
    *   Use the Vercel AI SDK's streaming or completion utilities (as appropriate) to send the crafted prompt + user question to the LLM and receive the generated database query.
3.  **Database Interaction:**
    *   Execute the database query generated by the LLM against the application's database.
    *   **Important:** Use parameterized queries or proper sanitization techniques to prevent SQL injection vulnerabilities when executing the AI-generated query.
    *   Fetch the results from the database.
4.  **Response Formatting:**
    *   Format the database results into a clear and understandable JSON response. Examples:
        *   For a count: `{ "answer_type": "count", "value": 15, "summary": "Arbitrator X had 15 cases." }`
        *   For an average: `{ "answer_type": "average", "value": 5500.75, "summary": "The average award by Arbitrator Y was $5500.75." }`
        *   For a list: `{ "answer_type": "list", "items": ["Case A", "Case B", "Case C"], "summary": "Cases handled by Arbitrator Z: Case A, Case B, Case C." }`
        *   For errors: `{ "error": "Could not understand the question." }` or `{ "error": "Database query failed." }`
    *   Return this JSON response from the API endpoint.
5.  **Flexibility & Robustness:** The AI query generation should be flexible enough to handle variations in user phrasing for the supported question types. Include basic error handling for cases where the AI cannot generate a valid query or the database query fails.

**Sample Questions to Support:**
*   "how many arbitrations has Arbitrator X had?"
*   "How many times has Arbitrator Y ruled for the complainant?"
*   "what was the average award given by Arbitrator Y when ruling for complainant?"
*   "List the names of all the arbitrations handled by Arbitrator Z."
*   "How many times has Arbitrator X ruled for the consumer against Coinbase?"
*   "how many cases have been filed against coinbase?"
*   "list all the arbitrators in cases where Coinbase was a party"
*   "what is the average award amount in cases against Chase"

**Technical Details (YOU MUST PROVIDE THESE):**
*   **Backend Framework:** [e.g., Node.js/Express, Python/Flask, Next.js API Routes]
*   **Open AI LLM Provider for Vercel AI SDK:** 
*   
*   **Existing File Structure (Optional but helpful):** [e.g., "Add the API route to `pages/api/query_ai.js`", "Create a new service in `services/nlp_query.py`"]

**Action:** Please implement the backend API endpoint `/api/query_ai` as described above, incorporating the Vercel AI SDK for SQL generation based on the user's natural language question and the provided schema. 